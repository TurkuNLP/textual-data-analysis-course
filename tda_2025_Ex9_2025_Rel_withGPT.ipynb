{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/ZLGLP9F/n5Zri6AYxYoR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/textual-data-analysis-course/blob/main/tda_2025_Ex9_2025_Rel_withGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Binary relation extraction**\n",
        "In this exercice, we will work on relation extraction part of the [Bacteria Biotope task at BioNLP Open Shared Tasks 2019.](https://aclanthology.org/D19-5719/).\n",
        "\n",
        "The task is a binary relation extraction, with three entity types:\n",
        "\n",
        "*  Microorganism (e.g. bacteria)\n",
        "*  Habitat (e.g. milk, cheese, etc)\n",
        "*  Geographical (e.g. Europe)\n",
        "\n",
        "and one binary relaiton type: *Lives_in*\n",
        "in the form of:\n",
        "*   *Lives_in*(Microorganism , Habitat)\n",
        "*   *Lives_in*(Microorganism , Geographical)\n",
        "\n",
        "Which is Positive if the sentence states that the Microorganism lives in the mentioned Habitat/Geographical and Negative, otherwise.\n",
        "\n",
        "Therefore, **candiate pairs** should be always created between (Microorganism , Habitat) and (Microorganism , Geographical), but other combinations are not logically meaningful.\n",
        "\n",
        "Each candidate pair, based on what the sentences states, can be Positive (in that case, we extract such relationship), or a Negative (in that case we do not extract that relation).\n",
        "\n",
        "Here is an example:\n",
        "* **Salmonella** was noticed in **raw chicken**. --> Positive --> *Lives_in* (Salmonella, raw chicken)\n",
        "* **Salmonella** was not noticed in **coocked chicken**. --> Negative\n",
        "\n",
        "The original task also includes one other relation type, but for simplicity, you will work with a converted dataset that only contains Lives_in relation.\n",
        "\n",
        "In this task you will use gpt-4o-mini with the api_key that was provided to you previously.\n",
        "\n",
        "Let's first donwload the training and development datasets."
      ],
      "metadata": {
        "id": "5UWz8POpH5qR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iA3Y_RabAH7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8def171-85bd-4edf-dce7-20fd415c04c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 14:24:39--  https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 362894 (354K) [text/plain]\n",
            "Saving to: ‘BB4_converted_train.json’\n",
            "\n",
            "BB4_converted_train 100%[===================>] 354.39K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-11 14:24:39 (7.42 MB/s) - ‘BB4_converted_train.json’ saved [362894/362894]\n",
            "\n",
            "--2025-02-11 14:24:39--  https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_devel.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 207477 (203K) [text/plain]\n",
            "Saving to: ‘BB4_converted_devel.json’\n",
            "\n",
            "BB4_converted_devel 100%[===================>] 202.61K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-11 14:24:40 (5.52 MB/s) - ‘BB4_converted_devel.json’ saved [207477/207477]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O BB4_converted_train.json https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_train.json\n",
        "!wget -O BB4_converted_devel.json https://raw.githubusercontent.com/TurkuNLP/textual-data-analysis-course/main/BB4_converted_devel.json\n",
        "!pip install --quiet openai pydantic scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's read the files and inspect their format."
      ],
      "metadata": {
        "id": "yFIucTUUBBaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def read_json(file_name):\n",
        "  with open(file_name, \"rt\" , encoding = 'utf-8') as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "train = read_json(\"BB4_converted_train.json\")\n",
        "devel = read_json(\"BB4_converted_devel.json\")\n",
        "\n",
        "print(\"training documents:\" , len(train))\n",
        "print(\"development documents:\" , len(devel))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUErKEoKQ855",
        "outputId": "4c75ca02-0694-4820-9a2d-2cbd3706672d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training documents: 125\n",
            "development documents: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's familiarize ourselves with file format."
      ],
      "metadata": {
        "id": "5YkG6c__SHK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (train.keys())\n",
        "train_doc_id = \"BB-rel-F-22177851-012\"\n",
        "for item in train[train_doc_id].items():\n",
        "  print (item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwS4q5lUSLyH",
        "outputId": "912e0b05-e0d7-4cd5-8b94-ac147e15faf7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['BB-rel-F-22177851-006', 'BB-rel-F-22177851-012', 'BB-rel-18845825', 'BB-rel-9526514', 'BB-rel-12970344', 'BB-rel-F-22177851-013', 'BB-rel-F-22177851-007', 'BB-rel-6143890', 'BB-rel-17237163', 'BB-rel-10738994', 'BB-rel-16990433', 'BB-rel-24678646', 'BB-rel-F-22177851-011', 'BB-rel-F-22177851-005', 'BB-rel-F-22177851-004', 'BB-rel-25634638', 'BB-rel-F-22177851-010', 'BB-rel-8607503', 'BB-rel-F-18524407-001', 'BB-rel-F-22177851-014', 'BB-rel-F-22177851-000', 'BB-rel-F-23290227-000', 'BB-rel-8347510', 'BB-rel-F-22177851-001', 'BB-rel-F-22177851-015', 'BB-rel-448557', 'BB-rel-F-18524407-000', 'BB-rel-14645268', 'BB-rel-11410343', 'BB-rel-21917915', 'BB-rel-F-22177851-003', 'BB-rel-F-22177851-017', 'BB-rel-9643457', 'BB-rel-F-22177851-002', 'BB-rel-16263187', 'BB-rel-F-25496341-009', 'BB-rel-6631408', 'BB-rel-24831788', 'BB-rel-2696427', 'BB-rel-F-25496341-008', 'BB-rel-19099664', 'BB-rel-F-23224222-009', 'BB-rel-F-23224222-008', 'BB-rel-16432479', 'BB-rel-25098305', 'BB-rel-24361838', 'BB-rel-24874563', 'BB-rel-9864452', 'BB-rel-607884', 'BB-rel-22834551', 'BB-rel-23908036', 'BB-rel-6107735', 'BB-rel-19175621', 'BB-rel-4329237', 'BB-rel-9798026', 'BB-rel-23855904', 'BB-rel-20073421', 'BB-rel-4105033', 'BB-rel-19396518', 'BB-rel-F-25496341-000', 'BB-rel-F-23224222-003', 'BB-rel-21924022', 'BB-rel-F-23224222-002', 'BB-rel-8997164', 'BB-rel-12781527', 'BB-rel-F-25496341-001', 'BB-rel-24198224', 'BB-rel-1016123', 'BB-rel-F-25496341-003', 'BB-rel-25562320', 'BB-rel-F-23224222-000', 'BB-rel-F-23224222-001', 'BB-rel-19501788', 'BB-rel-F-25496341-002', 'BB-rel-F-26678131-004', 'BB-rel-F-27020288-002', 'BB-rel-F-26678131-000', 'BB-rel-20148898', 'BB-rel-F-25496341-006', 'BB-rel-F-23224222-011', 'BB-rel-F-23224222-005', 'BB-rel-F-23224222-004', 'BB-rel-9255900', 'BB-rel-F-23224222-010', 'BB-rel-19622846', 'BB-rel-F-25496341-007', 'BB-rel-F-26678131-001', 'BB-rel-F-27020288-003', 'BB-rel-19049879', 'BB-rel-F-27020288-001', 'BB-rel-11437594', 'BB-rel-F-26678131-003', 'BB-rel-F-25496341-005', 'BB-rel-F-25496341-011', 'BB-rel-F-23224222-006', 'BB-rel-F-23224222-012', 'BB-rel-F-23224222-013', 'BB-rel-F-23224222-007', 'BB-rel-8532424', 'BB-rel-F-25496341-010', 'BB-rel-F-25496341-004', 'BB-rel-F-26678131-002', 'BB-rel-F-27020288-000', 'BB-rel-20005916', 'BB-rel-15358511', 'BB-rel-F-22177851-018', 'BB-rel-17687514', 'BB-rel-10658649', 'BB-rel-4328756', 'BB-rel-F-22177851-019', 'BB-rel-16436701', 'BB-rel-23702192', 'BB-rel-3074181', 'BB-rel-12728302', 'BB-rel-19075662', 'BB-rel-9564489', 'BB-rel-F-22177851-009', 'BB-rel-F-22177851-021', 'BB-rel-9535771', 'BB-rel-F-22177851-020', 'BB-rel-F-22177851-008', 'BB-rel-8358765', 'BB-rel-F-22177851-022', 'BB-rel-21498521', 'BB-rel-F-22177851-023'])\n",
            "('text', 'On the other hand, methylthiobutyrate, methyl ester octanoic acid, \\nbenzeneacetaldehyde and 3-heptanone were only found in the community \\nwith P. celer.\\n')\n",
            "('entities', {'T1': {'type': 'Habitat', 'offsets': [[127, 151]], 'text': 'community  with P. celer'}, 'T2': {'type': 'Microorganism', 'offsets': [[143, 151]], 'text': 'P. celer'}})\n",
            "('relations', {'R1': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T1', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, each document in the training or development set has a key, and it is a python dictionary, with \"text\" , \"entities\" , and \"relations\".\n",
        "\n",
        "* Entities have ids, starting with \"T\", type, and begining and end offsets in the text. **Some entities have multiple spans.**\n",
        "\n",
        "* Relations are also have ids, starting with \"R\" , and two arguments (entities). The first argument (e1), is always a Microorganism, and the second argument (e2) is either a \"Habitat\", or a \"Geographical\" location.\n",
        "\n",
        "**because this is manually annotated dataset, only positive pairs are annotated. We can generate all candidate pairs, and those that are annotated, are Positive examples, and those which we cannot find in the relations part, are the negative examples.**\n",
        "\n",
        "In above example, there is only one Habitat, one Microorganism, and one (Positive) relation between them.\n",
        "\n",
        "\n",
        "**But a document can have more than two entities and relations. Here is an example**"
      ],
      "metadata": {
        "id": "emjPPVgeSkp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc_id = \"BB-rel-F-22177851-006\"\n",
        "print (\"TEXT=\", train[train_doc_id]['text'])\n",
        "print (\"Entities:\")\n",
        "for entity_id in train[train_doc_id]['entities']:\n",
        "  print (entity_id , \":\" , train[train_doc_id]['entities'][entity_id])\n",
        "\n",
        "print (\"Positive relations:\")\n",
        "for positive_relation_id in train[train_doc_id]['relations']:\n",
        "  print(positive_relation_id, \":\" , train[train_doc_id]['relations'][positive_relation_id])\n",
        "print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQXz6x68aO_t",
        "outputId": "33fe3dd5-aa3d-4a34-8630-f06bcff07428"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT= The strain S3 + and its protease-negative variant S3-, assigned to Lactococcus lactis sp. lactis, was used for cheese-making. The 11 microorganisms that composed the model community included seven bacteria — Lactobacillus casei FH1, Arthrobacter arilaitensis Re117, Corynebacterium casei Mu120, C. flavescens Mu128, C. variabile Mu129, Staphylococcus xylosus Com1 and S. equorum Mu2 — and four yeasts — D. hansenii DH68, G. candidum GC129, Y. lipolytica CI35 and K. lactis\n",
            " KL65. This composition is representative of the diversity of smear soft\n",
            " cheese. The microorganisms were originally isolated from Munster except\n",
            " for Re117 (Reblochon), Com1 (unknown) and FH1 (St. Nectaire). The \n",
            "Gram-negative bacteria studied, P. celer 91 and H. alvei\n",
            " 2 920, isolated from Livarot and Munster cheese, respectively, were \n",
            "chosen from a large cheese bacteria collection for their low level of \n",
            "sanitary risk (sensitivity to 24 antibiotics, no production of biogenic \n",
            "amines in synthetic media and no growth under anaerobic condition and at\n",
            " 37 °C) (Coton et al., 2012).\n",
            "\n",
            "Entities:\n",
            "T1 : {'type': 'Microorganism', 'offsets': [[11, 15], [67, 96]], 'text': 'S3\\xa0+ Lactococcus lactis sp. lactis'}\n",
            "T3 : {'type': 'Microorganism', 'offsets': [[50, 53], [67, 96]], 'text': 'S3- Lactococcus lactis sp. lactis'}\n",
            "T4 : {'type': 'Habitat', 'offsets': [[111, 117]], 'text': 'cheese'}\n",
            "T5 : {'type': 'Habitat', 'offsets': [[166, 181]], 'text': 'model community'}\n",
            "T6 : {'type': 'Microorganism', 'offsets': [[208, 231]], 'text': 'Lactobacillus casei FH1'}\n",
            "T7 : {'type': 'Microorganism', 'offsets': [[233, 264]], 'text': 'Arthrobacter arilaitensis Re117'}\n",
            "T8 : {'type': 'Microorganism', 'offsets': [[266, 293]], 'text': 'Corynebacterium casei Mu120'}\n",
            "T9 : {'type': 'Microorganism', 'offsets': [[295, 314]], 'text': 'C. flavescens Mu128'}\n",
            "T10 : {'type': 'Microorganism', 'offsets': [[316, 334]], 'text': 'C. variabile Mu129'}\n",
            "T11 : {'type': 'Microorganism', 'offsets': [[336, 363]], 'text': 'Staphylococcus xylosus Com1'}\n",
            "T12 : {'type': 'Microorganism', 'offsets': [[368, 382]], 'text': 'S. equorum Mu2'}\n",
            "T13 : {'type': 'Microorganism', 'offsets': [[403, 419]], 'text': 'D. hansenii DH68'}\n",
            "T14 : {'type': 'Microorganism', 'offsets': [[421, 438]], 'text': 'G. candidum GC129'}\n",
            "T15 : {'type': 'Microorganism', 'offsets': [[440, 458]], 'text': 'Y. lipolytica CI35'}\n",
            "T16 : {'type': 'Microorganism', 'offsets': [[463, 478]], 'text': 'K. lactis  KL65'}\n",
            "T17 : {'type': 'Habitat', 'offsets': [[535, 553]], 'text': 'smear soft  cheese'}\n",
            "T18 : {'type': 'Habitat', 'offsets': [[604, 611]], 'text': 'Munster'}\n",
            "T19 : {'type': 'Microorganism', 'offsets': [[624, 629]], 'text': 'Re117'}\n",
            "T20 : {'type': 'Habitat', 'offsets': [[631, 640]], 'text': 'Reblochon'}\n",
            "T21 : {'type': 'Microorganism', 'offsets': [[643, 647]], 'text': 'Com1'}\n",
            "T22 : {'type': 'Microorganism', 'offsets': [[662, 665]], 'text': 'FH1'}\n",
            "T23 : {'type': 'Habitat', 'offsets': [[667, 679]], 'text': 'St. Nectaire'}\n",
            "T25 : {'type': 'Microorganism', 'offsets': [[719, 730]], 'text': 'P. celer 91'}\n",
            "T26 : {'type': 'Microorganism', 'offsets': [[735, 750]], 'text': 'H. alvei  2 920'}\n",
            "T27 : {'type': 'Habitat', 'offsets': [[766, 773]], 'text': 'Livarot'}\n",
            "T28 : {'type': 'Habitat', 'offsets': [[778, 792]], 'text': 'Munster cheese'}\n",
            "T29 : {'type': 'Habitat', 'offsets': [[834, 840]], 'text': 'cheese'}\n",
            "T32 : {'type': 'Habitat', 'offsets': [[968, 983]], 'text': 'synthetic media'}\n",
            "Positive relations:\n",
            "R1 : {'type': 'Lives_In', 'e1': 'T1', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R2 : {'type': 'Lives_In', 'e1': 'T3', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R4 : {'type': 'Lives_In', 'e1': 'T6', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R5 : {'type': 'Lives_In', 'e1': 'T6', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R6 : {'type': 'Lives_In', 'e1': 'T7', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R7 : {'type': 'Lives_In', 'e1': 'T7', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R8 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R9 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R10 : {'type': 'Lives_In', 'e1': 'T8', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R11 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R12 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R13 : {'type': 'Lives_In', 'e1': 'T9', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R14 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R15 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R16 : {'type': 'Lives_In', 'e1': 'T10', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R17 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R18 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R19 : {'type': 'Lives_In', 'e1': 'T11', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R20 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R21 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R22 : {'type': 'Lives_In', 'e1': 'T12', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R23 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R24 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R25 : {'type': 'Lives_In', 'e1': 'T13', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R26 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R27 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R28 : {'type': 'Lives_In', 'e1': 'T14', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R29 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R30 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R31 : {'type': 'Lives_In', 'e1': 'T15', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R32 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T17', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R33 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R34 : {'type': 'Lives_In', 'e1': 'T16', 'e2': 'T18', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R35 : {'type': 'Lives_In', 'e1': 'T19', 'e2': 'T20', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R36 : {'type': 'Lives_In', 'e1': 'T22', 'e2': 'T23', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R37 : {'type': 'Lives_In', 'e1': 'T25', 'e2': 'T32', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R38 : {'type': 'Lives_In', 'e1': 'T25', 'e2': 'T27', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R41 : {'type': 'Lives_In', 'e1': 'T26', 'e2': 'T32', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "R42 : {'type': 'Lives_In', 'e1': 'T26', 'e2': 'T28', 'e1_type': 'Microorganism', 'e2_type': 'Location'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's make a function that can tag entity spans, based on entity types:"
      ],
      "metadata": {
        "id": "6zo8_RpSa8L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_entities_with_entity_tags(text, entities):\n",
        "    \"\"\"\n",
        "    Annotate text with XML-like tags inserted directly into the text.\n",
        "\n",
        "    For each entity we assume the structure:\n",
        "      { \"type\": <entity type>, \"offsets\": [[start, end]], \"text\": <...> }\n",
        "\n",
        "    Overlapping annotations will be handled by inserting tags at the boundaries.\n",
        "    (If spans cross rather than nest, the output may have crossing tags; in many\n",
        "    applications you would split such spans to get a well-formed nesting.)\n",
        "\n",
        "    Returns:\n",
        "      A new string with opening and closing tags inserted.\n",
        "      For example: <Habitat>experimental smear soft cheese</Habitat>\n",
        "    \"\"\"\n",
        "    events = []\n",
        "    # For each entity (each value in the dictionary) add a start event and an end event.\n",
        "    for ent in entities.values():\n",
        "        tag = ent[\"type\"]\n",
        "        for start, end in ent[\"offsets\"]:\n",
        "            # Save event as (position, event_type, auxiliary, tag)\n",
        "            # For a start event, we record the end position as auxiliary (so we can sort descending by end)\n",
        "            # For an end event, we record the start position (so we can sort ascending by start).\n",
        "            events.append((start, \"start\", end, tag))\n",
        "            events.append((end, \"end\", start, tag))\n",
        "\n",
        "    # Define a sort key so that:\n",
        "    #   - Primary: sort by position.\n",
        "    #   - At the same position, \"end\" events come before \"start\" events.\n",
        "    #   - For start events at the same position, those with later (higher) end come first (so that outer tags open first).\n",
        "    #   - For end events at the same position, those with earlier start come first.\n",
        "    def event_sort_key(e):\n",
        "        pos, etype, aux, tag = e\n",
        "        if etype == \"end\":\n",
        "            return (pos, 0, aux)  # lower auxiliary value first\n",
        "        else:  # \"start\"\n",
        "            return (pos, 1, -aux)  # higher aux (later end) first\n",
        "\n",
        "    events.sort(key=event_sort_key)\n",
        "\n",
        "    # Now, we iterate over the sorted events and insert tag strings at the appropriate positions.\n",
        "    # We'll build a list of (position, string_to_insert) items.\n",
        "    inserts = []\n",
        "    for pos, etype, aux, tag in events:\n",
        "        if etype == \"end\":\n",
        "            inserts.append((pos, f\"</{tag}>\"))\n",
        "        else:\n",
        "            inserts.append((pos, f\"<{tag}>\"))\n",
        "\n",
        "    # Because multiple inserts may occur at the same position, group them.\n",
        "    # We already sorted events so that the insertions are in the correct order.\n",
        "    # Now, build the annotated text by iterating through the text and inserting tags at the right offsets.\n",
        "    result = []\n",
        "    last_index = 0\n",
        "    for pos, insert_text in inserts:\n",
        "        # Append the text between the last index and current position.\n",
        "        if pos > last_index:\n",
        "            result.append(text[last_index:pos])\n",
        "        # Append the tag.\n",
        "        result.append(insert_text)\n",
        "        last_index = pos\n",
        "    # Append any remaining text.\n",
        "    result.append(text[last_index:])\n",
        "    return \"\".join(result)\n",
        "\n",
        "train_doc_id = \"BB-rel-607884\"\n",
        "for item in train[train_doc_id].items():\n",
        "  print (item)\n",
        "\n",
        "print (\"-\"*80)\n",
        "text = train[train_doc_id]['text']\n",
        "entities = train[train_doc_id]['entities']\n",
        "print (\"ORIGINAL TEXT :  \", text)\n",
        "print (\"ENCODED TEXT :   \", mark_entities_with_entity_tags(text, entities))\n",
        "print (\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2HTQ5VV_9M",
        "outputId": "03ca4d65-f514-49de-b65a-0940aad25fd2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('text', '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n')\n",
            "('entities', {'T2': {'type': 'Microorganism', 'offsets': [[22, 30]], 'text': 'Serratia'}, 'T3': {'type': 'Habitat', 'offsets': [[39, 68]], 'text': 'Hospital S. Camillo De Lellis'}, 'T4': {'type': 'Geographical', 'offsets': [[72, 76]], 'text': 'Roma'}, 'T5': {'type': 'Geographical', 'offsets': [[78, 83]], 'text': 'Italy'}})\n",
            "('relations', {'R1': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R2': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T3', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R3': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T4', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n",
            "--------------------------------------------------------------------------------\n",
            "ORIGINAL TEXT :   [The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author's transl)].\n",
            "\n",
            "\n",
            "ENCODED TEXT :    [The infections from \"<Microorganism>Serratia</Microorganism>\" in the <Habitat>Hospital S. Camillo De Lellis</Habitat> of <Geographical>Roma</Geographical> (<Geographical>Italy</Geographical>) (author's transl)].\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are two possibilities now:**\n",
        "1. Marking full texts with all entities, and asking GPT to extract all possible relations Lives_in(Microorganism, Habitat/Geographical), and hope for the best.\n",
        "But then we will need to process the output for an accurate evaluation, **which can get tricky**.\n",
        "\n",
        "2. Generative all possible positive and negative pairs, assign them unique relation id, then feeding each example separately to GPT (or pack them together), and asking for predicting the label to be positive or negative.\n",
        "\n",
        "Here is the second approach:"
      ],
      "metadata": {
        "id": "yTLHnTn8epC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def generate_and_mark_all_candidate_pairs(_dataset):\n",
        "  unique_relation_id_index = 0\n",
        "  results = []\n",
        "  for document_id in _dataset:\n",
        "    text = _dataset[document_id]['text']\n",
        "    entities = _dataset[document_id]['entities']\n",
        "    ent_microorganisms = [e_id for e_id in entities if entities[e_id]['type'] == \"Microorganism\"]\n",
        "    ent_locations = [e_id for e_id in entities if entities[e_id]['type'] in [\"Geographical\", \"Habitat\"]]\n",
        "    # generate all possible pairs\n",
        "    candidate_pairs = list(product(ent_microorganisms, ent_locations))\n",
        "\n",
        "    # look at relations to get information about all positive pairs\n",
        "    relations = _dataset[document_id]['relations']\n",
        "    positive_pairs = (relations.items())\n",
        "    positive_pairs = set([(b['e1'], b['e2']) for (a, b) in relations.items()])\n",
        "\n",
        "    for (a, b) in candidate_pairs:\n",
        "      this_example_entities = dict()\n",
        "      this_example_entities[a] = entities[a]\n",
        "      this_example_entities[b] = entities[b]\n",
        "      if (a, b) in positive_pairs:\n",
        "        this_example_label = \"Positive\"\n",
        "      else:\n",
        "        this_example_label = \"Negative\"\n",
        "\n",
        "      ml_example = {\"UID\" : \"UID_\" + str(unique_relation_id_index),\n",
        "                    \"doc_id\": document_id,\n",
        "                    \"e1\" : a ,\n",
        "                    \"e2\" : b ,\n",
        "                    \"text\": text,\n",
        "                    \"marked_text\": mark_entities_with_entity_tags(text, this_example_entities),\n",
        "                    \"label\": this_example_label}\n",
        "      results.append(ml_example)\n",
        "      unique_relation_id_index += 1\n",
        "  return results\n",
        "\n",
        "train_examples = generate_and_mark_all_candidate_pairs(train)\n",
        "devel_examples = generate_and_mark_all_candidate_pairs(devel)\n",
        "\n",
        "for example in train_examples:\n",
        "  if example['doc_id'] == \"BB-rel-607884\":\n",
        "    print(example)\n",
        "print(\"-\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoD6pT_efRzG",
        "outputId": "028f52a5-208a-49aa-b236-87a7947afcf2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'UID': 'UID_3158', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T3', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the <Habitat>Hospital S. Camillo De Lellis</Habitat> of Roma (Italy) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
            "{'UID': 'UID_3159', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T4', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the Hospital S. Camillo De Lellis of <Geographical>Roma</Geographical> (Italy) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
            "{'UID': 'UID_3160', 'doc_id': 'BB-rel-607884', 'e1': 'T2', 'e2': 'T5', 'text': '[The infections from \"Serratia\" in the Hospital S. Camillo De Lellis of Roma (Italy) (author\\'s transl)].\\n\\n', 'marked_text': '[The infections from \"<Microorganism>Serratia</Microorganism>\" in the Hospital S. Camillo De Lellis of Roma (<Geographical>Italy</Geographical>) (author\\'s transl)].\\n\\n', 'label': 'Positive'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is another document with id = BB-rel-F-22177851-000\n",
        "\n"
      ],
      "metadata": {
        "id": "fNcQXK2Vpsta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train[\"BB-rel-F-22177851-000\"].items():\n",
        "  print (item)\n",
        "print (\"-\"*40)\n",
        "for example in train_examples:\n",
        "  if example['doc_id'] == \"BB-rel-F-22177851-000\":\n",
        "    print(example)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1cVW0jpzu4",
        "outputId": "5ac4acc1-faf8-4dfe-e429-e034064531b4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('text', 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n')\n",
            "('entities', {'T2': {'type': 'Microorganism', 'offsets': [[62, 81]], 'text': 'Psychrobacter celer'}, 'T3': {'type': 'Microorganism', 'offsets': [[86, 98]], 'text': 'Hafnia alvei'}, 'T4': {'type': 'Habitat', 'offsets': [[132, 187]], 'text': 'microbial community of an experimental smear soft chees'}, 'T5': {'type': 'Habitat', 'offsets': [[158, 188]], 'text': 'experimental smear soft cheese'}})\n",
            "('relations', {'R2': {'type': 'Lives_In', 'e1': 'T2', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}, 'R4': {'type': 'Lives_In', 'e1': 'T3', 'e2': 'T5', 'e1_type': 'Microorganism', 'e2_type': 'Location'}})\n",
            "----------------------------------------\n",
            "{'UID': 'UID_856', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T2', 'e2': 'T4', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (<Microorganism>Psychrobacter celer</Microorganism> and Hafnia alvei) inoculated as part of the whole <Habitat>microbial community of an experimental smear soft chees</Habitat>e\\n', 'label': 'Negative'}\n",
            "{'UID': 'UID_857', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T2', 'e2': 'T5', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (<Microorganism>Psychrobacter celer</Microorganism> and Hafnia alvei) inoculated as part of the whole microbial community of an <Habitat>experimental smear soft cheese</Habitat>\\n', 'label': 'Positive'}\n",
            "{'UID': 'UID_858', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T3', 'e2': 'T4', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and <Microorganism>Hafnia alvei</Microorganism>) inoculated as part of the whole <Habitat>microbial community of an experimental smear soft chees</Habitat>e\\n', 'label': 'Negative'}\n",
            "{'UID': 'UID_859', 'doc_id': 'BB-rel-F-22177851-000', 'e1': 'T3', 'e2': 'T5', 'text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and Hafnia alvei) inoculated as part of the whole microbial community of an experimental smear soft cheese\\n', 'marked_text': 'Ecological and aromatic impact of two Gram-negative bacteria (Psychrobacter celer and <Microorganism>Hafnia alvei</Microorganism>) inoculated as part of the whole microbial community of an <Habitat>experimental smear soft cheese</Habitat>\\n', 'label': 'Positive'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look how many positive and negative examples are in the devel set:"
      ],
      "metadata": {
        "id": "m4ynhOPu2y4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos , neg = 0 , 0\n",
        "for example in devel_examples:\n",
        "  if example['label'] == 'Positive':\n",
        "    pos+=1\n",
        "  else:\n",
        "    neg+=1\n",
        "\n",
        "print (\"there are\" , pos , \"Positive examples in the devel set.\")\n",
        "print (\"there are\" , neg , \"Negative examples in the devel set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv47kyRuluNw",
        "outputId": "738c93dc-529a-4701-f6cc-352d3b584e96"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 453 Positive examples in the devel set.\n",
            "there are 6786 Negative examples in the devel set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's work with a subset of devel set:  "
      ],
      "metadata": {
        "id": "0j9o0xEY93_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 400 #text length\n",
        "filtered_devel = dict()\n",
        "for doc_id in devel:\n",
        "  if len(devel[doc_id]['text']) <= threshold:\n",
        "    filtered_devel[doc_id] = devel[doc_id]\n",
        "\n",
        "print (\"documents in filtered devel:\", len(filtered_devel))\n",
        "filtered_devel_examples = generate_and_mark_all_candidate_pairs(filtered_devel)\n",
        "pos , neg = 0 , 0\n",
        "for example in filtered_devel_examples:\n",
        "  if example['label'] == \"Positive\":\n",
        "    pos+= 1\n",
        "  else:\n",
        "    neg+= 1\n",
        "\n",
        "print (\"positives in filtered devel: \" , pos)\n",
        "print (\"negatives in filtered devel: \" , neg)\n",
        "print (\"total: \" , pos + neg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8yPAkfo9_rU",
        "outputId": "e6917468-183c-4044-d84a-96c97e6707f1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents in filtered devel: 13\n",
            "positives in filtered devel:  46\n",
            "negatives in filtered devel:  45\n",
            "total:  91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "api_key = \"\" #use the code you were given in course ...\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "class MLExample(BaseModel):\n",
        "    UID: str\n",
        "    label: str  # Assuming 'positive' is a string\n",
        "\n",
        "class Preds(BaseModel):\n",
        "    data: List[MLExample]  # A list of Item dictionaries\n",
        "\n",
        "def get_predictions_from_GPT(user_prompt):\n",
        "  system_prompt = \"\"\"\n",
        "  Your task is to do binary relation extraction, for a few given input sentences.\n",
        "  Each given sentence has a unique identifier  (UID).\n",
        "  For each input sentence, you need to check if the mentioned <Microorganism>, lives in the mentioned <Habitat> (or <Geographical>, or not.\n",
        "  - If positive: you should return {\"UID\": UID of the example, \"label\": \"Positive\"}, a dictionary with UID: str, and Label =\"Positive\"\n",
        "  - If negative: you should return {\"UID\": UID of the example, \"label\": \"Negative\"}, a dictionary with UID: str, and Label =\"Negative\"\n",
        "\n",
        "  you can pack all the results, and give the output as a list of dictionaries.\n",
        "  \"\"\"\n",
        "  completion = client.beta.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_prompt},\n",
        "      {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        "    response_format=Preds,\n",
        "  )\n",
        "\n",
        "  message = completion.choices[0].message\n",
        "  preds = completion.choices[0].message.parsed\n",
        "  return (message, preds)\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "In the following sentences, check if the mentioned microrganism (e.g. bacteria), lives in the mentioned habitat/geographical entity or not.\n",
        "For each input sentence, you need to check if the mentioned <Microorganism>, lives in the mentioned <Habitat> (or <Geographical>, or not.\"\n",
        "\n",
        "UID: 0  Text = <Microorganism>Salmonella</Microorganism> was noticed in <Habitat>raw chicken</Habitat>.\n",
        "UID: 1  Text = <Microorganism>Salmonella</Microorganism> was not noticed in <Habitat>coocked chicken</Habitat>.\n",
        "\"\"\"\n",
        "res = get_predictions_from_GPT(user_prompt)\n",
        "print (res[1].data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbNzLvYpBmmG",
        "outputId": "0d027ca4-1645-4a66-82e1-9784cb0450a0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MLExample(UID='0', label='Positive'), MLExample(UID='1', label='Negative')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have 3 tasks:\n",
        "\n",
        "**Task1:**\n",
        "\n",
        "Write a code that predicts the labels for all examples in `filtered_devel_examples` (there a 91 examples in this set) by asking the GPT model. You **must** use a `for` loop that packs **5 examples in at-a-time** (in each iteration of the for loop), and predicts the labels for them at once. This is to keep GPT costs low (a real situation if you're going to work for a company). Then use `sklearn.metrics.precision_recall_fscore_support` to calculate precision, recall, and f1-score for the `filtered_devel_examples`.\n",
        "Do **NOT **give any example inputs to the GPT (no few-shot learning in this step).\n",
        "\n",
        "**Task2:**\n",
        "\n",
        "now, include the two positive and negative sentence about Salmonella and chicken that I had mentioned, as examples in your prompts.  \n",
        "\n",
        "- \"UID: UID_1000  Text = <Microorganism>Salmonella</Microorganism> was noticed in <Habitat>raw chicken</Habitat>. --> {'UID':'UID_1000', label = 'Positive'}\n",
        "\n",
        "- \"UID: UID_1001  Text = <Microorganism>Salmonella</Microorganism> was not noticed in <Habitat>coocked chicken</Habitat>. --> {'UID':'UID_1001', label = 'Negative'}\"\n",
        "\n",
        "and repeat the experiment, and report precision, recall, and f1-score.\n",
        "How the results have changed?\n",
        "\n",
        "**Task3:**\n",
        "\n",
        "3.1 Now **randomly** select 4 examples from the **training set** (you can take 2 positives, 2 negatives, or really sample randomly) and include them in your prompt, repeat the experiment, report precision, recall, and f1-score.\n",
        "How the results have changed?\n",
        "\n",
        "3.2 Repeat above experiment: Again, **randomly** sample 4 training examples and use them **instead** of the 4 previous examples. Have the results changed? **Why?**  \n",
        "\n",
        "In order not to get a time-out error from GPT call, you can increas the timeout, **but also make sure you sample from smaller texts.**"
      ],
      "metadata": {
        "id": "Vx1n7VtZV7Hf"
      }
    }
  ]
}