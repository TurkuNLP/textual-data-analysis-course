{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/textual-data-analysis-course/blob/main/model_explainability_qa_solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mcnYVMdYDf_"
      },
      "source": [
        "# Model load\n",
        "\n",
        "* Now we load the model and repeat some of the imports so it is possible to run the notebook from this point onwards"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVAOAdx5UITk",
        "outputId": "29629802-e527-42bb-ce4c-b002d9e423cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dl.turkunlp.org/TKO_8964_2023/english-binarized-weighted.model.tgz\n",
        "!tar zxvf english-binarized-weighted.model.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GplFzSrjToQa",
        "outputId": "ce7e1302-c8eb-4b6c-85c7-9ba17c3c2e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-12 20:37:42--  http://dl.turkunlp.org/TKO_8964_2023/english-binarized-weighted.model.tgz\n",
            "Resolving dl.turkunlp.org (dl.turkunlp.org)... 195.148.30.23\n",
            "Connecting to dl.turkunlp.org (dl.turkunlp.org)|195.148.30.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 402134026 (384M) [application/octet-stream]\n",
            "Saving to: ‘english-binarized-weighted.model.tgz’\n",
            "\n",
            "english-binarized-w 100%[===================>] 383.50M  20.1MB/s    in 21s     \n",
            "\n",
            "2023-02-12 20:38:03 (18.5 MB/s) - ‘english-binarized-weighted.model.tgz’ saved [402134026/402134026]\n",
            "\n",
            "english-binarized-weighted.model/\n",
            "english-binarized-weighted.model/training_args.bin\n",
            "english-binarized-weighted.model/pytorch_model.bin\n",
            "english-binarized-weighted.model/tokenizer.json\n",
            "english-binarized-weighted.model/vocab.txt\n",
            "english-binarized-weighted.model/config.json\n",
            "english-binarized-weighted.model/special_tokens_map.json\n",
            "english-binarized-weighted.model/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99hMGMUra14q"
      },
      "source": [
        "# relevant stuff repeated from above so you can run it from here onwards if you happen to have the model trained\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "\n",
        "MODEL_NAME = 'english-binarized-weighted.model'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocPeVRnPWF_m"
      },
      "source": [
        "import torch\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to('cpu')    # simplifies input placement\n",
        "\n",
        "label_names = [\n",
        "    'no_answer',\n",
        "    'does_answer'\n",
        "]\n",
        "\n",
        "def predict_qa(question,context):\n",
        "    tokenized = tokenizer(text=question, text_pair=context, return_tensors='pt')\n",
        "    pred = model(**tokenized)\n",
        "    pred_idx = pred.logits.detach().numpy().argmax()\n",
        "    return label_names[pred_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-up4Ua7iMMO"
      },
      "source": [
        "try that out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_QcEfttZgn9",
        "outputId": "0be38929-6a6b-4078-b20c-723bb9d1db1b"
      },
      "source": [
        "example_pairs = [\n",
        "    {\"question\":\"When was University of Turku founded?\",\n",
        "     \"context\": \"\"\"The University of Turku (Finnish: Turun yliopisto,\n",
        "      in Swedish: Åbo universitet, shortened UTU), located in Turku in\n",
        "      southwestern Finland, is the third largest university in the country\n",
        "      as measured by student enrollment, after the University of Helsinki\n",
        "      and Tampere University. It is a multidisciplinary university with \n",
        "      eight faculties. It was established in 1920 and also has facilities \n",
        "      at Rauma, Pori, Kevo and Seili. The university is a member of \n",
        "      the Coimbra Group and the European Campus of City-Universities (EC2U).\"\"\"\n",
        "     }\n",
        "]\n",
        "\n",
        "for e in example_pairs:\n",
        "    print(e[\"question\"], '->', predict_qa(**e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When was University of Turku founded? -> does_answer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2oGRF0ssbYh"
      },
      "source": [
        "# Model explainability with the captum library\n",
        "\n",
        "* captum.ai is a nifty library with many of the explainability algorithms implemented\n",
        "* we will use it here to try the techniques\n",
        "* this is not the easiest of code, btw, many of the libraries are bleeding-edge, so you cut yourself here and there (the blood on the edge is yours)\n",
        "* the code below is (quite substantial) adaptation of https://captum.ai/tutorials/Bert_SQUAD_Interpret"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz69yC5EbkFA",
        "outputId": "729740b4-a979-4413-c5cd-f3e6ab816a78"
      },
      "source": [
        "!pip install captum pandas matplotlib seaborn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting captum\n",
            "  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum) (1.13.1+cu116)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (4.4.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRDMMKWtb1DU"
      },
      "source": [
        "from captum.attr import visualization as viz\n",
        "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7ieBNPfcJF8"
      },
      "source": [
        "#Tells the model that it is in evaluation mode, and zeroes out the gradients\n",
        "model.eval()\n",
        "model.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV52we4xGJK2"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmHmhdRAeMW6"
      },
      "source": [
        "# Forward on the model -> data in, prediction out, nothing fancy really\n",
        "def predict(input_ids,token_type_ids,attention_mask):\n",
        "    pred=model(input_ids,token_type_ids=token_type_ids,attention_mask=attention_mask)\n",
        "    return pred.logits #return the output of the classification layer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rQx10XHpRmq"
      },
      "source": [
        "def construct_input_ref_pair(question,context):\n",
        "    inp=tokenizer(text=question,text_pair=context,return_tensors=\"pt\")\n",
        "    #how long is the context?\n",
        "    context_tok=tokenizer(context,add_special_tokens=False)[\"input_ids\"]\n",
        "    ref=tokenizer(text=question,text_pair=\" \".join([\"[PAD]\"]*len(context_tok)),return_tensors=\"pt\")\n",
        "    return (inp[\"input_ids\"], inp[\"token_type_ids\"], inp[\"attention_mask\"]),\\\n",
        "    (ref[\"input_ids\"], ref[\"token_type_ids\"], ref[\"attention_mask\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfUPcEF_vx9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f03249e-fd5d-4a43-989f-0fb397c77dc4"
      },
      "source": [
        "inp,ref=construct_input_ref_pair(**example_pairs[0])\n",
        "p=predict(*inp)\n",
        "print(\"p=\",p)\n",
        "print(\"p.shape\",p.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p= tensor([[-1.4038,  1.4566]], grad_fn=<AddmmBackward0>)\n",
            "p.shape torch.Size([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yEjjc7_xcy1"
      },
      "source": [
        "# Yay, now we finally made it to the attribution part\n",
        "lig = LayerIntegratedGradients(predict, model.bert.embeddings) #attribute the output wrt to embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDeDDO2Lx1JG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87313d56-924e-4689-e513-29adf8e6d033"
      },
      "source": [
        "# inputs: inputs\n",
        "# baselines: the blank baseline\n",
        "# target: which of the two classes in the output (pos/neg) to run the prediction against?\n",
        "\n",
        "\n",
        "\n",
        "attrs, delta = lig.attribute(inputs=inp,\n",
        "                                  baselines=ref,\n",
        "                                  return_convergence_delta=True,target=1)\n",
        "print(\"attrs shape\",attrs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attrs shape torch.Size([1, 134, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgn5rRRZyZgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b3977d-b7ac-4647-dfee-f4623f8e8bf6"
      },
      "source": [
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.linalg.vector_norm(attributions,dim=0)\n",
        "    return attributions\n",
        "\n",
        "attrs_sum = summarize_attributions(attrs)\n",
        "print(\"attrs_sum shape\",attrs_sum.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attrs_sum shape torch.Size([134])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmbI0pCIymt_",
        "outputId": "c4fa2309-2ecb-41e5-ddcd-f591706f2078"
      },
      "source": [
        "print(attrs_sum)\n",
        "print(tokenizer.convert_ids_to_tokens(inp[0][0]))\n",
        "\n",
        "for a,t in zip(attrs_sum,tokenizer.convert_ids_to_tokens(inp[0][0])):\n",
        "    print(float(a),t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         0.0000e+00,  5.1144e-02,  1.0043e-01,  1.0590e-01,  8.0828e-02,\n",
            "         9.2856e-02,  1.0488e-01,  3.4153e-02,  6.0640e-02,  2.1290e-03,\n",
            "         2.2661e-02,  2.8650e-02,  3.1066e-02,  2.8959e-02,  7.3983e-03,\n",
            "         1.2038e-02, -1.3695e-03,  6.4360e-03,  1.1252e-02, -3.6065e-02,\n",
            "         5.7909e-03,  1.5247e-02, -7.5268e-03,  2.1909e-03, -2.0554e-02,\n",
            "        -9.2351e-04,  6.8407e-03,  2.5283e-03,  1.0588e-02, -1.2810e-02,\n",
            "        -1.4111e-02, -1.4266e-02, -1.4134e-03,  2.4064e-02,  4.5502e-02,\n",
            "         4.2195e-02,  6.4391e-02, -2.3645e-03,  2.5417e-02,  7.2869e-02,\n",
            "        -5.6970e-04, -2.7238e-02,  5.2433e-03,  5.7280e-02, -1.0741e-02,\n",
            "         6.3813e-02,  3.6112e-02,  2.1141e-02,  1.5774e-02,  3.3020e-02,\n",
            "        -1.4722e-02,  2.1891e-02,  5.6451e-02,  4.4617e-02,  3.6945e-02,\n",
            "         2.1848e-02, -9.2404e-03,  2.1187e-01,  2.9484e-02,  3.4847e-02,\n",
            "         2.9809e-02, -1.7801e-02, -6.6626e-03, -1.9255e-03,  1.1133e-01,\n",
            "         1.7076e-02, -2.3149e-02,  1.0393e-02, -7.2961e-03,  1.7374e-02,\n",
            "        -3.1363e-03,  3.9386e-02,  4.0147e-03,  5.0754e-03, -4.6688e-03,\n",
            "        -3.3758e-02,  4.3521e-02,  5.7137e-03,  2.2478e-01, -1.4610e-01,\n",
            "         8.5775e-01, -1.5407e-01, -2.0217e-02, -1.5133e-02, -2.1912e-02,\n",
            "         3.9885e-02,  1.0773e-02, -4.8802e-03, -2.1449e-02, -3.0371e-03,\n",
            "        -1.4113e-03, -6.1899e-03,  8.5457e-03,  5.2622e-03, -7.5015e-03,\n",
            "         4.6578e-03, -1.4976e-02,  1.8554e-02, -7.6285e-03,  2.3233e-02,\n",
            "         4.4146e-03,  3.7918e-03,  3.8675e-03,  7.5955e-03,  1.5168e-02,\n",
            "         4.3199e-03,  1.4938e-03, -6.3300e-03,  9.7854e-03, -1.0085e-02,\n",
            "         1.2304e-02,  1.5031e-02, -1.6314e-02,  1.2885e-02,  1.0011e-02,\n",
            "         3.2466e-03, -1.0312e-02, -1.3682e-02,  4.8805e-03, -4.9081e-03,\n",
            "         8.6052e-03, -1.9523e-02,  1.2423e-02,  0.0000e+00],\n",
            "       dtype=torch.float64)\n",
            "['[CLS]', 'When', 'was', 'University', 'of', 'Tu', '##rk', '##u', 'founded', '?', '[SEP]', 'The', 'University', 'of', 'Tu', '##rk', '##u', '(', 'Finnish', ':', 'Tu', '##run', 'y', '##lio', '##pis', '##to', ',', 'in', 'Swedish', ':', 'Å', '##bo', 'un', '##ivers', '##ite', '##t', ',', 'shortened', 'U', '##TU', ')', ',', 'located', 'in', 'Tu', '##rk', '##u', 'in', 'southwestern', 'Finland', ',', 'is', 'the', 'third', 'largest', 'university', 'in', 'the', 'country', 'as', 'measured', 'by', 'student', 'enrollment', ',', 'after', 'the', 'University', 'of', 'Helsinki', 'and', 'Tam', '##per', '##e', 'University', '.', 'It', 'is', 'a', 'multi', '##disciplinary', 'university', 'with', 'eight', 'faculties', '.', 'It', 'was', 'established', 'in', '1920', 'and', 'also', 'has', 'facilities', 'at', 'Ra', '##uma', ',', 'Po', '##ri', ',', 'Ke', '##vo', 'and', 'Se', '##ili', '.', 'The', 'university', 'is', 'a', 'member', 'of', 'the', 'Co', '##im', '##bra', 'Group', 'and', 'the', 'European', 'Campus', 'of', 'City', '-', 'Universities', '(', 'EC', '##2', '##U', ')', '.', '[SEP]']\n",
            "0.0 [CLS]\n",
            "0.0 When\n",
            "0.0 was\n",
            "0.0 University\n",
            "0.0 of\n",
            "0.0 Tu\n",
            "0.0 ##rk\n",
            "0.0 ##u\n",
            "0.0 founded\n",
            "0.0 ?\n",
            "0.0 [SEP]\n",
            "0.051144035204891025 The\n",
            "0.10042767174516701 University\n",
            "0.10589551898195414 of\n",
            "0.08082770464141588 Tu\n",
            "0.09285592015098221 ##rk\n",
            "0.10488001072564833 ##u\n",
            "0.034153455112652616 (\n",
            "0.060639544393632214 Finnish\n",
            "0.002129014931423523 :\n",
            "0.022661072489132995 Tu\n",
            "0.028650027696084778 ##run\n",
            "0.031065562826198986 y\n",
            "0.028958989524240874 ##lio\n",
            "0.007398342246329096 ##pis\n",
            "0.012038454351744205 ##to\n",
            "-0.0013694934379369858 ,\n",
            "0.006435953376727324 in\n",
            "0.011251972205379938 Swedish\n",
            "-0.03606498462011328 :\n",
            "0.005790899976705719 Å\n",
            "0.015247001664670093 ##bo\n",
            "-0.007526779435946911 un\n",
            "0.0021909464496679123 ##ivers\n",
            "-0.020554088555782987 ##ite\n",
            "-0.0009235086463644086 ##t\n",
            "0.006840744566660655 ,\n",
            "0.0025283008787986335 shortened\n",
            "0.010587927847467196 U\n",
            "-0.012809815191692268 ##TU\n",
            "-0.014110811487815273 )\n",
            "-0.01426619477014497 ,\n",
            "-0.0014134060782296119 located\n",
            "0.0240644929827035 in\n",
            "0.04550245072462918 Tu\n",
            "0.04219521257149432 ##rk\n",
            "0.06439059083574533 ##u\n",
            "-0.0023645141990265425 in\n",
            "0.025416939445925726 southwestern\n",
            "0.0728690440050392 Finland\n",
            "-0.0005697038501357868 ,\n",
            "-0.027237528165094785 is\n",
            "0.0052432774681293905 the\n",
            "0.05727959561252763 third\n",
            "-0.010741131022463693 largest\n",
            "0.06381347155739726 university\n",
            "0.036112162823570486 in\n",
            "0.021140985599508735 the\n",
            "0.01577395995763966 country\n",
            "0.033020129300196585 as\n",
            "-0.014722427013662675 measured\n",
            "0.02189104157788916 by\n",
            "0.05645107656410667 student\n",
            "0.04461660689645317 enrollment\n",
            "0.036944806930365004 ,\n",
            "0.021847764676863387 after\n",
            "-0.009240376072623445 the\n",
            "0.21187235058414608 University\n",
            "0.029483715429070485 of\n",
            "0.03484672232754724 Helsinki\n",
            "0.02980904415991996 and\n",
            "-0.01780074451689627 Tam\n",
            "-0.006662572577076925 ##per\n",
            "-0.0019254945184981206 ##e\n",
            "0.11132654937446496 University\n",
            "0.017076036472862502 .\n",
            "-0.02314936127581158 It\n",
            "0.010393354499936915 is\n",
            "-0.007296096337816762 a\n",
            "0.01737373024704087 multi\n",
            "-0.003136258200941432 ##disciplinary\n",
            "0.039386377091885874 university\n",
            "0.004014712118258059 with\n",
            "0.005075372396417407 eight\n",
            "-0.004668812641232698 faculties\n",
            "-0.03375784968875924 .\n",
            "0.04352066187169316 It\n",
            "0.005713741220003632 was\n",
            "0.22477938688053128 established\n",
            "-0.14610264525850528 in\n",
            "0.8577525425789166 1920\n",
            "-0.15407236765896118 and\n",
            "-0.020216982346411127 also\n",
            "-0.015132943633555749 has\n",
            "-0.02191155805030534 facilities\n",
            "0.03988466477579219 at\n",
            "0.010773390546038264 Ra\n",
            "-0.004880175535440605 ##uma\n",
            "-0.021449030968759056 ,\n",
            "-0.003037076298094408 Po\n",
            "-0.0014113429672252585 ##ri\n",
            "-0.006189892281542515 ,\n",
            "0.008545697043012269 Ke\n",
            "0.00526216714412712 ##vo\n",
            "-0.007501514176451904 and\n",
            "0.004657779716417876 Se\n",
            "-0.014975756231273415 ##ili\n",
            "0.018553947690869863 .\n",
            "-0.0076285147636944465 The\n",
            "0.02323345915461211 university\n",
            "0.004414636687527718 is\n",
            "0.00379184250059071 a\n",
            "0.0038675178773945064 member\n",
            "0.007595542532280289 of\n",
            "0.015167687812420767 the\n",
            "0.004319853015361182 Co\n",
            "0.0014937711539347405 ##im\n",
            "-0.006330011004211947 ##bra\n",
            "0.009785441097972655 Group\n",
            "-0.010084692861338045 and\n",
            "0.012304078328832332 the\n",
            "0.015031115341130259 European\n",
            "-0.01631448880782136 Campus\n",
            "0.012885409747227886 of\n",
            "0.010010630564961601 City\n",
            "0.0032466145687793024 -\n",
            "-0.010312083410163974 Universities\n",
            "-0.01368249175616509 (\n",
            "0.004880535170522865 EC\n",
            "-0.004908115317544407 ##2\n",
            "0.008605181127823032 ##U\n",
            "-0.01952302892083755 )\n",
            "0.012423208872182312 .\n",
            "0.0 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "238tqqadDPbq"
      },
      "source": [
        "Damn, that seems to work!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "mjvnyJLaOhWK",
        "outputId": "fa5061e6-1a77-4214-e37a-34ae7945d6a1"
      },
      "source": [
        "import captum\n",
        "from IPython.core.display import HTML, display\n",
        "x=captum.attr.visualization.format_word_importances(tokenizer.convert_ids_to_tokens(inp[0][0]),attrs_sum)\n",
        "HTML(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> When                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> University                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Tu                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##rk                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##u                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> founded                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ?                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> University                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Tu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##rk                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##u                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Finnish                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Tu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##run                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> y                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lio                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##pis                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Swedish                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> :                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Å                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##bo                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> un                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ivers                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ite                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shortened                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> U                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##TU                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> located                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Tu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##rk                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##u                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> southwestern                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Finland                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> third                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> largest                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> country                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> measured                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> by                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> student                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enrollment                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> after                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> University                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Helsinki                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Tam                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##per                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##e                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> University                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> multi                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##disciplinary                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> with                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eight                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> faculties                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> established                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(120, 75%, 58%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 1920                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> also                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> has                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> facilities                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> at                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ra                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##uma                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Po                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ri                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ke                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##vo                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Se                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ili                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> The                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> university                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> member                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Co                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##im                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##bra                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Group                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> the                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> European                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Campus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> of                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> City                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> -                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Universities                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> (                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> EC                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##2                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##U                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> )                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ]
}