{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnmmjR2/bgFGL1ZhfQOJNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/textual-data-analysis-course/blob/main/text_classification_dataset_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification dataset examples\n",
        "\n",
        "Let's have a look at some text classification datasets from the Hugging Face datasets repository (https://huggingface.co/datasets).\n",
        "\n",
        "(You can find a tutorial to `datasets` here: https://huggingface.co/docs/datasets/tutorial)\n",
        "\n",
        "First, install the `datasets` Python package:"
      ],
      "metadata": {
        "id": "PoamCQ7gRSOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "HTtSPJiFRNQm"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make loading a bit less verbose. (This only affects what shows on screen when loading.)"
      ],
      "metadata": {
        "id": "kGtnpTPKTNMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import disable_progress_bar\n",
        "\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "tGyI08cPTIkO"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll mainly use the `load_dataset` function to download data from the repository by name. To see what's available for this task, you can navigate to https://huggingface.co/datasets and select \"text classification\" from the filters. You can also use `load_dataset_builder` for information on a dataset, as shown in the following."
      ],
      "metadata": {
        "id": "BBPfBoivR2Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: IMDB\n",
        "\n",
        "You might already be familiar with this one. (Here, `pprint` is a pretty-printing library)"
      ],
      "metadata": {
        "id": "olVO4LerbCXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_dataset_builder\n",
        "from pprint import pprint\n",
        "\n",
        "builder = load_dataset_builder('imdb')\n",
        "\n",
        "print(builder.info.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tfL47DWRp5M",
        "outputId": "b8fad020-d45f-459a-d82e-15cd4dc1581d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb = load_dataset('imdb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAI4H4zgdNM2",
        "outputId": "eaec99f7-2e62-4c5a-94ea-dfc0f9d96e33"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the dataset object shows a summary of its contents:"
      ],
      "metadata": {
        "id": "h095kek3YGXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyKi5Cf_YCGb",
        "outputId": "159eff20-d832-4f6f-8ae5-75c246e3d9f0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here we have three parts:\n",
        "\n",
        "* `train`: 25,000 examples\n",
        "* `test`: 25,000 examples\n",
        "* `unsupervised`: 50,000 examples\n",
        "\n",
        "(The former two are conventional, the last atypical.)\n",
        "\n",
        "Each example has a `text` and a `label`.\n",
        "\n",
        "Let's look at an example:"
      ],
      "metadata": {
        "id": "v1h7JPqjYQMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(imdb['train'][0]['text'])\n",
        "print('\\nLabel:', imdb['train'][0]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRHTr8CpST21",
        "outputId": "2590c487-582f-4b6d-836d-c7b1f27e8804"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I rented I AM CURIOUS-YELLOW from my video store because of all the '\n",
            " 'controversy that surrounded it when it was first released in 1967. I also '\n",
            " 'heard that at first it was seized by U.S. customs if it ever tried to enter '\n",
            " 'this country, therefore being a fan of films considered \"controversial\" I '\n",
            " 'really had to see this for myself.<br /><br />The plot is centered around a '\n",
            " 'young Swedish drama student named Lena who wants to learn everything she can '\n",
            " 'about life. In particular she wants to focus her attentions to making some '\n",
            " 'sort of documentary on what the average Swede thought about certain '\n",
            " 'political issues such as the Vietnam War and race issues in the United '\n",
            " 'States. In between asking politicians and ordinary denizens of Stockholm '\n",
            " 'about their opinions on politics, she has sex with her drama teacher, '\n",
            " 'classmates, and married men.<br /><br />What kills me about I AM '\n",
            " 'CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. '\n",
            " \"Really, the sex and nudity scenes are few and far between, even then it's \"\n",
            " 'not shot like some cheaply made porno. While my countrymen mind find it '\n",
            " 'shocking, in reality sex and nudity are a major staple in Swedish cinema. '\n",
            " 'Even Ingmar Bergman, arguably their answer to good old boy John Ford, had '\n",
            " 'sex scenes in his films.<br /><br />I do commend the filmmakers for the fact '\n",
            " 'that any sex shown in the film is shown for artistic purposes rather than '\n",
            " 'just to shock people and make money to be shown in pornographic theaters in '\n",
            " 'America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the '\n",
            " 'meat and potatoes (no pun intended) of Swedish cinema. But really, this film '\n",
            " \"doesn't have much of a plot.\")\n",
            "\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the `label` is just the value `0`. To interpret this, we can look at `features`:"
      ],
      "metadata": {
        "id": "vKuYsCshZvx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb['train'].features['label'].names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7mYglnzYON_",
        "outputId": "b6426f8a-804f-482e-a093-e9584a6174dc"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the label `0` corresponds to `neg` (negative) and the label `1` to `pos` (positive). "
      ],
      "metadata": {
        "id": "qebipkGCaJ9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Example: `emotion`\n",
        "\n",
        "Following the same process as above:"
      ],
      "metadata": {
        "id": "GIgp17W6a_sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = load_dataset_builder('emotion')\n",
        "\n",
        "print(builder.info.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpEbxnHtdtVm",
        "outputId": "4ce32bfd-aab0-489d-9a21-f0101fff382f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:No config specified, defaulting to: emotion/split\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion = load_dataset('emotion')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZngtHHu4aH0-",
        "outputId": "108f457e-2dae-4f45-b0b4-d7852624d47c"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:No config specified, defaulting to: emotion/split\n",
            "WARNING:datasets.builder:Found cached dataset emotion (/root/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ztQcntbT8j",
        "outputId": "446a49e0-1c6b-443d-fcde-b65fc60f51c5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, three parts:\n",
        "\n",
        "* `train`: 16,000 examples\n",
        "* `validation`: 2000 examples\n",
        "* `test`: 2000 examples\n",
        "\n",
        "(This is a common way to partition a dataset that you should already be familiar with.)"
      ],
      "metadata": {
        "id": "rvmC2c3TcOZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(emotion['train'][0]['text'])\n",
        "print('\\nLabel:', emotion['train'][0]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEDEdnkmbg3g",
        "outputId": "c590e71a-27da-46e0-e39a-f6d5c595db49"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'i didnt feel humiliated'\n",
            "\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotion['train'].features['label'].names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwO1chGcqpI",
        "outputId": "216e485c-89c9-4a5b-c4ad-770b8c60c464"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Example: SNLI"
      ],
      "metadata": {
        "id": "klzDi1TEfaX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = load_dataset_builder('snli')\n",
        "\n",
        "print(builder.info.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpmpGbpefebf",
        "outputId": "3408d580-ee03-4636-c9ff-040a04006d18"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The SNLI corpus (version 1.0) is a collection of 570k human-written English\n",
            "sentence pairs manually labeled for balanced classification with the labels\n",
            "entailment, contradiction, and neutral, supporting the task of natural language\n",
            "inference (NLI), also known as recognizing textual entailment (RTE).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snli = load_dataset('snli')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl78T8HNfiSq",
        "outputId": "7c09d333-e54f-47a7-85ba-8503990df823"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset snli (/root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(snli)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkPKTbHIgHLY",
        "outputId": "19644ef8-1e6d-4dfb-e819-791ef19c1060"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 550152\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, the conventional three parts:\n",
        "\n",
        "* `train`: 550,152 examples\n",
        "* `validation`: 10,000 examples\n",
        "* `test`: 10,000 examples\n",
        "\n",
        "However, this time instead of just `text` and `label` we have `premise`, `hypothesis`, and `label`:"
      ],
      "metadata": {
        "id": "CaySYAmBgYuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(snli['train'][0]['premise'])\n",
        "pprint(snli['train'][0]['hypothesis'])\n",
        "print('\\nLabel:', snli['train'][0]['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hT7N8ygLJz",
        "outputId": "7a94120a-e330-4ba5-8f77-6ef046092552"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'A person on a horse jumps over a broken down airplane.'\n",
            "'A person is training his horse for a competition.'\n",
            "\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(snli['train'].features['label'].names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XbDYEJSg0S-",
        "outputId": "87708ef6-ad3c-4176-a082-c7d67f061a06"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['entailment', 'neutral', 'contradiction']\n"
          ]
        }
      ]
    }
  ]
}